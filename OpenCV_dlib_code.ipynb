{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efde792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "#———-Model File Paths—————-#\n",
    "\n",
    "ageProto=\"age_deploy.prototxt\"\n",
    "\n",
    "ageModel=\"age_net.caffemodel\"\n",
    "\n",
    "#———–Model Variables—————#\n",
    "\n",
    "mean =(78.4263377603, 87.7689143744, 114.895847746) # these are taken from the official site\n",
    "\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "\n",
    "#————-Creating the DNN————#\n",
    "\n",
    "age_Net= cv2.dnn.readNet(ageModel,ageProto)\n",
    "\n",
    "img = cv2.imread('sample.jpg')\n",
    "#img = cv2.resize(img, (720, 640))\n",
    "frame = img.copy()\n",
    "\n",
    "# ------------ Model for Age detection --------#\n",
    "age_weights = \"age_deploy.prototxt\"\n",
    "age_config = \"age_net.caffemodel\"\n",
    "age_Net = cv2.dnn.readNet(age_config, age_weights)\n",
    "\n",
    "# Model requirements for image\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
    "\t\t'(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "model_mean = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# storing the image dimensions\n",
    "fH = img.shape[0]\n",
    "fW = img.shape[1]\n",
    "\n",
    "Boxes = [] # to store the face co-ordinates\n",
    "mssg = 'Face Detected' # to display on image\n",
    "\n",
    "# ------------- Model for face detection---------#\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "# converting to grayscale\n",
    "img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# -------------detecting the faces--------------#\n",
    "faces = face_detector(img_gray)\n",
    "\n",
    "# If no faces our detected\n",
    "if not faces:\n",
    "\tmssg = 'No face detected'\n",
    "\tcv2.putText(img, f'{mssg}', (40, 40),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 2, (200), 2)\n",
    "\tcv2.imshow('Age detected', img)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "else:\n",
    "\t# --------- Bounding Face ---------#\n",
    "\tfor face in faces:\n",
    "\t\tx = face.left() # extracting the face coordinates\n",
    "\t\ty = face.top()\n",
    "\t\tx2 = face.right()\n",
    "\t\ty2 = face.bottom()\n",
    "\n",
    "\t\t# rescaling those coordinates for our image\n",
    "\t\tbox = [x, y, x2, y2]\n",
    "\t\tBoxes.append(box)\n",
    "\t\tcv2.rectangle(frame, (x, y), (x2, y2),\n",
    "\t\t\t\t\t(00, 200, 200), 2)\n",
    "\n",
    "\tfor box in Boxes:\n",
    "\t\tface = frame[box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "\t\t# ----- Image preprocessing --------#\n",
    "\t\tblob = cv2.dnn.blobFromImage(\n",
    "\t\t\tface, 1.0, (227, 227), model_mean, swapRB=False)\n",
    "\n",
    "\t\t# -------Age Prediction---------#\n",
    "\t\tage_Net.setInput(blob)\n",
    "\t\tage_preds = age_Net.forward()\n",
    "\t\tage = ageList[age_preds[0].argmax()]\n",
    "\n",
    "\t\tcv2.putText(frame, f'{mssg}:{age}', (box[0],\n",
    "\t\t\t\t\t\t\t\t\t\t\tbox[1] - 10),\n",
    "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "\t\t\t\t\t(0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\t\tcv2.imshow(\"Detecting Age\", frame)\n",
    "\t\tcv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8263f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc1e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
